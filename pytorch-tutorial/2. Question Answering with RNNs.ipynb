{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Answering with RNNs\n",
    "\n",
    "There are many structured prediction tasks in machine learning, and many of them involve sequences - particularly sequences of text - in some form. Some examples include sentiment analysis (text to single class), image captioning (single image to text) and machine translation (text to text). Recurrent neural networks (RNNs) are a good fit for such problems, particularly when the sequences involved have an explicit or implicit ordering to the items; conversely, one might find other architectures more suitable if the input is a set. RNNs not only take in and output a single input and output at a time, but also have a hidden state vector which can be used to integrate information over time. They can have more complex units, such as long short-term memory (LSTM) units, that alleviate problems such as vanishing gradients, and be combined with other modules to enable bidirectional reading or attention or memory mechanisms.\n",
    "\n",
    "We'll focus on text-based question answering, using RNNs to read a story, a query, and predict the answer. This can, broadly speaking, encapsulate several natural language processing (NLP) tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "We'll use the first task from the 20 tasks of the bAbI dataset. This procedurally generated dataset was designed to test text understanding and reasoning, and includes tasks such as answering yes/no questions, counting items, performing coreference resolution, and even basic deduction. In each task there is a story to read, a question, and the answer, with 1000 examples for training and 1000 for testing per task. The first task is based on answering a question with a single supporting fact - we'll set up datasets to iterate over and show an example below. By the standards of the dataset, we'll be looking at a *weakly supervised* setting, as opposed to the *strongly supervised* setting where the indices of the supporting facts (out of all of the facts) are also provided during training.\n",
    "\n",
    "We'll use `torchtext`, which provides the dataset in a more convenient form. `torchtext` provides several NLP functions, such as tokenisation, as well as helpers for dealing with training on text data. There tends to be a lot of data processing for dealing with text, so it's worth consulting the documentation and other material for how to make use of the package. Here we'll get training and test datasets, along with metadata about the text (such as the vocabulary size)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import ticker\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchtext import datasets\n",
    "from IPython.display import clear_output, display\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_example(example):\n",
    "    story, query, answer = '\\n'.join(' '.join(s) for s in example.story), ' '.join(example.query), ' '.join(example.answer)\n",
    "    print('Story:\\n%s\\n-------------------------------------------------\\nQuery: %s?\\nAnswer: %s' % (story, query, answer))\n",
    "\n",
    "data_path = os.path.join(os.path.expanduser('~'), '.torch', 'datasets', 'babi')\n",
    "train_data, _, test_data = datasets.BABI20.iters(task=1, batch_size=32, root=data_path)\n",
    "STORY, QUERY, ANSWER = [train_data.dataset.fields[f] for f in ['story', 'query', 'answer']]\n",
    "print_example(train_data.dataset[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "We'll use a combination of models to deal with the different inputs and produce an output. Firstly, we'll use a bidirectional LSTM to read the story, as it will be able to better preserve information across larger sequences (that are provided at once - only unidirectional RNNs can be used for online sequences). Secondly, we'll use a unidirectional LSTM to read the question, and use the final output to \"attend\" to the sentence states of the story RNN. Finally, this will be passed to a fully-connected network to predict the output (the answers are single words here, so there is no need for an RNN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 128\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, zeros_idx, bidirectional=False):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_size, padding_idx=zeros_idx)\n",
    "        self.rnn = nn.LSTM(hidden_size, hidden_size, bidirectional=bidirectional)\n",
    "\n",
    "    def forward(self, x, h=None):\n",
    "        x = self.embedding(x)\n",
    "        if x.dim() == 4:  # Sum embeddings over a sentence in the story encoder\n",
    "            x = x.sum(2)\n",
    "        x, _ = self.rnn(x, h)\n",
    "        return x\n",
    "\n",
    "class QANetwork(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super().__init__()\n",
    "        self.s_encoder = Encoder(len(STORY.vocab), hidden_size // 2, zeros_idx=STORY.vocab.stoi['pad'], bidirectional=True)\n",
    "        self.q_encoder = Encoder(len(QUERY.vocab), hidden_size, zeros_idx=STORY.vocab.stoi['pad'])\n",
    "        self.a_generator = nn.Sequential(nn.Linear(hidden_size, hidden_size),\n",
    "                                         nn.Dropout(0.8),\n",
    "                                         nn.ReLU(),\n",
    "                                         nn.Linear(hidden_size, len(ANSWER.vocab)))\n",
    "\n",
    "    def forward(self, x, h=None):\n",
    "        s = self.s_encoder(x.story)\n",
    "        q = self.q_encoder(x.query)[:, -1]\n",
    "        attention = F.softmax(torch.einsum('bsh,bh->bs', [s, q]), dim=1).unsqueeze(2)\n",
    "        a = torch.sum(attention * s, 1)\n",
    "        a = self.a_generator(a)\n",
    "        return a, attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing\n",
    "\n",
    "We'll train the network for a few epochs and plot the training and test losses. We can also visualise the attention of the network over the story, showing which parts it thinks are relevant for answering the question at hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = QANetwork(hidden_size)\n",
    "optimiser = optim.Adam(model.parameters(), lr=0.0005)\n",
    "train_losses, test_losses, test_acc = [], [], 0\n",
    "epochs, iters_per_epoch = 10, len(train_data)\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "plotted_legend = False\n",
    "\n",
    "\n",
    "def plot():\n",
    "    global plotted_legend\n",
    "    plt.plot(range(len(train_losses)), train_losses, 'b-', label='Train')\n",
    "    plt.plot([(i + 1) * iters_per_epoch - 1 for i in range(len(test_losses))], test_losses, 'r-', label='Test')\n",
    "    clear_output(wait=True)\n",
    "    display(plt.gcf())\n",
    "    if not plotted_legend:\n",
    "        plt.legend(loc='upper right')\n",
    "        plotted_legend = True\n",
    "\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    for i, x in enumerate(train_data):\n",
    "        optimiser.zero_grad()\n",
    "        y_hat, _ = model(x)\n",
    "        loss = F.cross_entropy(y_hat, x.answer.squeeze(1))\n",
    "        loss.backward()\n",
    "        train_losses.append(loss.item())\n",
    "        optimiser.step()\n",
    "        if i % 10 == 0:\n",
    "            plot()\n",
    "\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for x in test_data:\n",
    "            y_hat, _ = model(x)\n",
    "            test_loss += F.cross_entropy(y_hat, x.answer.squeeze(1), reduction='sum').item()\n",
    "            pred = y_hat.argmax(1, keepdim=True)\n",
    "            correct += pred.eq(x.answer).sum().item()\n",
    "\n",
    "    test_losses.append(test_loss / len(test_data.dataset))\n",
    "    return correct / len(test_data.dataset)\n",
    "\n",
    "\n",
    "for _ in range(epochs):\n",
    "    train()\n",
    "    test_acc = test()\n",
    "plot()\n",
    "clear_output(wait=True)\n",
    "display('Final test accuracy: %.2f%%' % (test_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "x = next(iter(test_data))\n",
    "with torch.no_grad():\n",
    "    y_hat, attention = model(x)\n",
    "example_id = 8\n",
    "example = test_data.dataset[example_id]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "cax = ax.matshow(attention[example_id, :len(example.story) - 1].numpy(), cmap='bone')\n",
    "ax.set_title(' '.join(example.query) + '?')\n",
    "ax.set_yticklabels(' '.join(s) for s in example.story)\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "ax.xaxis.set_major_locator(ticker.NullLocator())\n",
    "fig.colorbar(cax)\n",
    "display(plt.gcf())\n",
    "clear_output(wait=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
